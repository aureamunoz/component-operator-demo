version: 2.1

executors:
  k8s-executor:
    machine:
      image: ubuntu-1604:201903-01
      docker_layer_caching: true
    environment:
      KUBE_VERSION: v1.14.0
      MINIKUBE_HOME: $HOME
      KUBECONFIG: $HOME/.kube/config
      OPERATOR_GIT_REF: master

jobs:
  k8s-setup-start:
    executor: k8s-executor
    steps:
    - run:
        name: Install kubectl, Helm
        command: |
          curl -LO https://storage.googleapis.com/kubernetes-release/release/${KUBE_VERSION}/bin/linux/amd64/kubectl
          chmod +x ./kubectl && sudo mv ./kubectl /usr/local/bin/kubectl

          curl -L https://git.io/get_helm.sh | bash

    - run:
        name: Install microk8s
        command: |
          sudo snap install microk8s --classic

          # wait until a k8s node is ready
          sleep 10
          n=0
          until [ $n -ge 15 ]
          do
            (/snap/bin/microk8s.kubectl get no | grep -z "Ready") && break
            n=$[$n+1]
            sleep 20
          done
          echo "Kubernetes cluster launched"

          # Allow intra-pod communication
          sudo iptables -P FORWARD ACCEPT

    - run:
        name: Enable Services dns & storage
        command: |
          /snap/bin/microk8s.enable dns registry storage

    - run:
        name: Enable Services Ingress
        command: |
          /snap/bin/microk8s.enable ingress

    - run:
        name: Initialize helm
        command: |
          helm init

          until kubectl get pods -n kube-system -l name=tiller | grep 1/1; do sleep 1; done

          kubectl create clusterrolebinding tiller-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:default

    - run:
        name: Install ServiceCatalog using helm
        command: |
          # Adds the chart repository for the service catalog
          helm repo add svc-cat https://svc-catalog-charts.storage.googleapis.com

          # Installs the service catalog
          helm install svc-cat/catalog --name catalog --namespace catalog

          # Wait until the catalog is ready before moving on
          until kubectl get pods -n catalog -l app=catalog-catalog-apiserver | grep 2/2; do sleep 1; done
          until kubectl get pods -n catalog -l app=catalog-catalog-controller-manager | grep 1/1; do sleep 1; done

    - run:
        name: Install OpenShift Ansible Broker
        command: |
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/master/deploy/oab-install.yaml
          until kubectl get pods -n automation-broker -l app=automation-broker | grep 2/2; do sleep 10; done

    - run:
        name: Install Component Operator from master branch
        command: |
          kubectl create namespace component-operator
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/sa.yaml -n component-operator
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/cluster-rbac.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/user-rbac.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/crds/capability_v1alpha2.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/crds/component_v1alpha2.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/crds/link_v1alpha2.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/operator.yaml -n component-operator

    - checkout
    - restore_cache:
        keys:
          - demo
    - run:
        name: dependencies
        command: |
          mvn dependency:go-offline || true
    - save_cache:
        paths:
          - ~/.m2
        key: demo
    - run:
        name: Compile the component-operator-demo project using maven
        command: |
          mvn clean package -DskipTests=true

    # Following run will fail as we still have 2 ap4k issues to be fixed
    # See: https://github.com/ap4k/ap4k/issues/225
    # See: https://github.com/snowdrop/component-operator/issues/48
    #- run:
    #    name: Deploy the yaml resources populated by ap4k within the demo namespace
    #    command: |
    #      kubectl create namespace demo
    #      kubectl apply -n demo -f fruit-backend-sb/target/classes/META-INF/ap4k/component.yml
    #      kubectl apply -n demo -f fruit-client-sb/target/classes/META-INF/ap4k/component.yml

    - run:
        name: Deploy the CORRECT yaml resources within the demo namespace
        command: |
          kubectl create namespace demo
          echo "Deploy fruit-backend-sb"
          cat \<<EOF | kubectl apply -f -
          ---
          apiVersion: "v1"
          kind: "List"
          items:
          - apiVersion: "devexp.runtime.redhat.com/v1alpha2"
            kind: "Capability"
            metadata:
              name: "postgresql-db"
            spec:
              name: "postgresql-db"
              class: "dh-postgresql-apb"
              plan: "dev"
              secretName: "postgresql-db"
              parameters:
              - name: "postgresql_user"
                value: "luke"
              - name: "postgresql_password"
                value: "secret"
              - name: "postgresql_database"
                value: "my_data"
              - name: "postgresql_version"
                value: "9.6"
          - apiVersion: "devexp.runtime.redhat.com/v1alpha2"
            kind: "Component"
            metadata:
              labels:
                app: "fruit-backend-sb"
                version: "0.0.1-SNAPSHOT"
                group: "dabou"
              name: "fruit-backend-sb"
            spec:
              name: "fruit-backend-sb"
              deploymentMode: "dev"
              runtime: "spring-boot"
              version: "2.1.3.RELEASE"
              exposeService: true
              envs:
              - name: "SPRING_PROFILES_ACTIVE"
                value: "openshift-catalog"
          - apiVersion: "devexp.runtime.redhat.com/v1alpha2"
            kind: "Link"
            metadata:
              name: "link-to-database"
            spec:
              name: "link-to-database"
              componentName: "fruit-backend-sb"
              kind: "Secret"
              ref: "postgresql-db"
          EOF

          echo "Deploy fruit-client-sb"
          cat \<<EOF | kubectl apply -f -
          ---
          apiVersion: "v1"
          kind: "List"
          items:
          - apiVersion: "devexp.runtime.redhat.com/v1alpha2"
            kind: "Component"
            metadata:
              labels:
                app: "fruit-client-sb"
                version: "0.0.1-SNAPSHOT"
                group: "dabou"
              name: "fruit-client-sb"
            spec:
              deploymentMode: "dev"
              runtime: "spring-boot"
              version: "2.1.3.RELEASE"
              exposeService: true
          - apiVersion: "devexp.runtime.redhat.com/v1alpha2"
            kind: "Link"
            metadata:
              name: "link-to-fruit-backend"
            spec:
              name: "link-to-fruit-backend"
              kind: "Env"
              componentName: "fruit-client-sb"
              ref: ""
              envs:
              - name: "OPENSHIFT_ENDPOINT_BACKEND"
                value: "http://fruit-backend-sb:8080/api/fruits"
          EOF

    - run:
        name: Wait till the fruit-backend, fruit-client have been started
        command: |
          sleep 10
          n=0
          until [ $n -ge 10 ]
          do
            (kubectl get pods -l app=fruit-backend-sb -n demo | grep 1/1) && break
            kubectl get pods -l app=fruit-backend-sb -n demo
            n=$[$n+1]
            sleep 10
          done
          echo "fruit-backend-sb deployed"

          n=0
          until [ $n -ge 10 ]
          do
            (kubectl get pods -l app=fruit-client-sb -n demo | grep 1/1) && break
            kubectl get pods -l app=fruit-client-sb -n demo
            n=$[$n+1]
            sleep 10
          done
          echo "fruit-client-sb deployed"

          kubectl get pods -n demo

    - run:
        name: Push now the uber jar file of the frontend, backend
        command: |
          ./scripts/k8s_push_start.sh fruit-backend sb demo
          ./scripts/k8s_push_start.sh fruit-client sb demo

    - run:
        name: Logs Frontend and backend logs
        command: |
          declare -a arr=("fruit-client-sb" "fruit-backend-sb")
          namespace=demo
          mkdir -p $CIRCLE_WORKING_DIRECTORY/logs

          for i in "${arr[@]}"
          do
             pod_name=$(kubectl get pod -l app=$i -o name -n ${namespace})
             pod_id=${pod_name#"pod/"}
             echo "Log app: $i"
             kubectl logs -n ${namespace} ${pod_id} > $CIRCLE_WORKING_DIRECTORY/$i.txt
          done
    - store_artifacts:
        path: $CIRCLE_WORKING_DIRECTORY/logs

    - run:
        name: Check if the client can get the fruits from the backend/db
        command: |
          kubectl describe ing/fruit-client-sb -n demo
          curl -H "Host: fruit-client-sb" 127.0.0.1/api/client

workflows:
  version: 2.1
  test-component-operator-demo:
    jobs:
      - k8s-setup-start