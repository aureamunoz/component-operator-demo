version: 2.0

executors:
  k8s-executor:
    machine:
      image: ubuntu-1604:201903-01
      docker_layer_caching: true
    environment:
      KUBE_VERSION: v1.14.0
      MINIKUBE_HOME: $HOME
      KUBECONFIG: $HOME/.kube/config
      OPERATOR_GIT_REF: master

jobs:
  k8s-setup-start:
    executor: k8s-executor
    steps:
    - run:
        name: Install kubectl, Helm
        command: |
          curl -LO https://storage.googleapis.com/kubernetes-release/release/${KUBE_VERSION}/bin/linux/amd64/kubectl
          chmod +x ./kubectl && sudo mv ./kubectl /usr/local/bin/kubectl

          curl -L https://git.io/get_helm.sh | bash

    - run:
        name: Install microk8s
        command: |
          sudo snap install microk8s --classic

          # wait until a k8s node is ready
          sleep 10
          n=0
          until [ $n -ge 15 ]
          do
            (/snap/bin/microk8s.kubectl get no | grep -z "Ready") && break
            n=$[$n+1]
            sleep 20
          done
          echo "Kubernetes cluster launched"

          # Allow intra-pod communication
          sudo iptables -P FORWARD ACCEPT

    - run:
        name: Enable Services dns & storage
        command: |
          /snap/bin/microk8s.enable dns registry storage

    - run:
        name: Enable Services Ingress
        command: |
          /snap/bin/microk8s.enable ingress

    - run:
        name: Initialize helm
        command: |
          helm init

          until kubectl get pods -n kube-system -l name=tiller | grep 1/1; do sleep 1; done

          kubectl create clusterrolebinding tiller-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:default

    - run:
        name: Install ServiceCatalog using helm
        command: |
          # Adds the chart repository for the service catalog
          helm repo add svc-cat https://svc-catalog-charts.storage.googleapis.com

          # Installs the service catalog
          helm install svc-cat/catalog --name catalog --namespace catalog

          # Wait until the catalog is ready before moving on
          until kubectl get pods -n catalog -l app=catalog-catalog-apiserver | grep 2/2; do sleep 1; done
          until kubectl get pods -n catalog -l app=catalog-catalog-controller-manager | grep 1/1; do sleep 1; done

    - run:
        name: Install OpenShift Ansible Broker
        command: |
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/master/deploy/oab-install.yaml
          until kubectl get pods -n automation-broker -l app=automation-broker | grep 2/2; do sleep 10; done

    - run:
        name: Install Component Operator from master branch
        command: |
          kubectl create namespace component-operator
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/sa.yaml -n component-operator
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/cluster-rbac.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/user-rbac.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/crds/capability_v1alpha2.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/crds/component_v1alpha2.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/crds/link_v1alpha2.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/operator.yaml -n component-operator

    - checkout
    - restore_cache:
        keys:
          - demo
    - run:
        name: dependencies
        command: |
          mvn dependency:go-offline || true
    - save_cache:
        paths:
          - ~/.m2
        key: demo
    - run:
        name: Compile the component-operator-demo project using maven
        command: |
          mvn clean package -DskipTests=true
    - run:
        name: Deploy the yaml resources populated by ap4k within the demo namespace
        command: |
          kubectl create namespace demo
          kubectl apply -n demo -f fruit-backend-sb/target/classes/META-INF/ap4k/component.yml
          kubectl apply -n demo -f fruit-client-sb/target/classes/META-INF/ap4k/component.yml

    - run:
        name: Wait till the fruit-backend, fruit-client have been started
        command: |
          until kubectl get pods -l app=fruit-backend-sb -n demo | grep 1/1; do sleep 10; done
          until kubectl get pods -l app=fruit-client-sb -n demo | grep 1/1; do sleep 10; done

    - run:
        name: Push now the uber jar file of the frontend, backend
        command: |
          ./scripts/k8s_push_start.sh fruit-backend sb demo
          ./scripts/k8s_push_start.sh fruit-client sb demo

    - run:
        name: Logs Frontend and backend logs
        command: |
          declare -a arr=("fruit-client-sb" "fruit-backend-sb")
          namespace=demo
          mkdir -p $HOME/artifacts/

          for i in "${arr[@]}"
          do
             pod_name=$(kubectl get pod -l app=$i -o name -n ${namespace})
             pod_id=${pod_name#"pod/"}
             echo "Log app: $i"
             kubectl logs -n ${namespace} ${pod_id} > $HOME/artifacts/$i.txt
          done
    - store_artifacts:
        path: $HOME/artifacts/
    - run:
        name: Check if the client can get the fruits from the backend/db
        command: |
          kubectl describe ing/fruit-client-sb -n demo
          curl -H "Host: fruit-client-sb" 127.0.0.1/api/client

workflows:
  version: 2.1
  test-component-operator-demo:
    jobs:
      - k8s-setup-start