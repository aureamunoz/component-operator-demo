version: 2.1

executors:
  k8s-executor:
    machine:
      image: ubuntu-1604:201903-01
      docker_layer_caching: true
    environment:
      KUBE_VERSION: v1.14.0
      MINIKUBE_HOME: $HOME
      KUBECONFIG: $HOME/.kube/config
      OPERATOR_GIT_REF: master

jobs:
  k8s-setup-start:
    executor: k8s-executor
    steps:
    #- run:
    #    name: Install Minikube
    #    command: |
    #      curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
    #      chmod +x minikube && sudo cp minikube /usr/local/bin && rm minikube
    #      mkdir -p "$HOME/.kube"
    #      mkdir -p "$HOME/.minikube"

    # Failing as we get
    # minikube is not running, so the service cannot be accessed
    # Exited with code 69
    #- run:
    #    name: Start minikube
    #    command: |
    #      minikube addons enable ingress
    #      minikube config set cpus 4
    #      minikube config set vm-driver none
    #      minikube config set kubernetes-version ${KUBE_VERSION}
    #      minikube start -v 6

    # Failing
    # E: Unable to locate package kubelet
    # E: Unable to locate package kubeadm
    # E: Unable to locate package kubectl
    # Exited with code 100
    # - run:
    #    name: Install kubelet, kubectl, kubeadmin
    #    command: |
    #      sudo apt-get install -y apt-transport-https
    #      curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
    #      sudo tee -a /etc/apt/sources.list.d/kubernetes.list \<<EOF
    #      deb https://apt.kubernetes.io/ kubernetes-xenial main
    #      EOF
    #      sudo apt-get install -y kubelet kubeadm kubectl
    #      sudo apt-mark hold kubelet kubeadm kubectl

    # Failing
    # Failed to execute operation: No such file or directory
    # Exited with code 1
    #- run:
    #    name: TODO
    #    command: |
    #      CNI_VERSION="v0.6.0"
    #      sudo mkdir -p /opt/cni/bin
    #      curl -L "https://github.com/containernetworking/plugins/releases/download/${CNI_VERSION}/cni-plugins-amd64-${CNI_VERSION}.tgz" | sudo tar -C /opt/cni/bin -xz
    #
    #      CRICTL_VERSION="v1.11.1"
    #      sudo mkdir -p /opt/bin
    #      curl -L "https://github.com/kubernetes-incubator/cri-tools/releases/download/${CRICTL_VERSION}/crictl-${CRICTL_VERSION}-linux-amd64.tar.gz" | sudo tar -C /opt/bin -xz
    #
    #      RELEASE="$(curl -sSL https://dl.k8s.io/release/stable.txt)"
    #
    #      cd /opt/bin
    #      sudo curl -L --remote-name-all https://storage.googleapis.com/kubernetes-release/release/${RELEASE}/bin/linux/amd64/{kubeadm,kubelet,kubectl}
    #      sudo chmod +x {kubeadm,kubelet,kubectl}
    #
    #      sudo systemctl enable --now kubelet
    - run:
        name: Install kubectl, Helm
        command: |
          curl -LO https://storage.googleapis.com/kubernetes-release/release/${KUBE_VERSION}/bin/linux/amd64/kubectl
          chmod +x ./kubectl && sudo mv ./kubectl /usr/local/bin/kubectl

          curl -L https://git.io/get_helm.sh | bash

    - run:
        name: Install microk8s
        command: |
          sudo snap install microk8s --classic

          # wait until a k8s node is ready
          sleep 10
          n=0
          until [ $n -ge 15 ]
          do
            (/snap/bin/microk8s.kubectl get no | grep -z "Ready") && break
            n=$[$n+1]
            sleep 20
          done
          echo "Kubernetes cluster launched"

          # Allow intra-pod communication
          sudo iptables -P FORWARD ACCEPT

    - run:
        name: Enable Services dns & storage
        command: |
          /snap/bin/microk8s.enable dns registry storage

    - run:
        name: Enable Services Ingress
        command: |
          /snap/bin/microk8s.enable ingress

    - run:
        name: Initialize helm
        command: |
          helm init

          until kubectl get pods -n kube-system -l name=tiller | grep 1/1; do sleep 1; done

          kubectl create clusterrolebinding tiller-cluster-admin --clusterrole=cluster-admin --serviceaccount=kube-system:default

    - run:
        name: Install ServiceCatalog using helm
        command: |
          # Adds the chart repository for the service catalog
          helm repo add svc-cat https://svc-catalog-charts.storage.googleapis.com

          # Installs the service catalog
          helm install svc-cat/catalog --name catalog --namespace catalog

          # Wait until the catalog is ready before moving on
          until kubectl get pods -n catalog -l app=catalog-catalog-apiserver | grep 2/2; do sleep 1; done
          until kubectl get pods -n catalog -l app=catalog-catalog-controller-manager | grep 1/1; do sleep 1; done

    - run:
        name: Install OpenShift Ansible Broker
        command: |
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/master/deploy/oab-install.yaml
          until kubectl get pods -n automation-broker -l app=automation-broker | grep 2/2; do sleep 10; done

    - run:
        name: Install Component Operator from master branch
        command: |
          kubectl create namespace component-operator
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/sa.yaml -n component-operator
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/cluster-rbac.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/user-rbac.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/crds/capability_v1alpha2.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/crds/component_v1alpha2.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/crds/link_v1alpha2.yaml
          kubectl apply -f https://raw.githubusercontent.com/snowdrop/component-operator/${OPERATOR_GIT_REF}/deploy/operator.yaml -n component-operator

    - checkout
    - restore_cache:
        keys:
          - demo
    - run:
        name: dependencies
        command: |
          mvn dependency:go-offline || true
    - save_cache:
        paths:
          - ~/.m2
        key: demo
    - run:
        name: Compile the component-operator-demo project using maven
        command: |
          mvn clean package -DskipTests=true
    - run:
        name: Deploy the yaml resources populated by ap4k within the demo namespace
        command: |
          kubectl create namespace demo
          kubectl apply -n demo -f fruit-backend-sb/target/classes/META-INF/ap4k/component.yml
          kubectl apply -n demo -f fruit-client-sb/target/classes/META-INF/ap4k/component.yml

    - run:
        name: Wait till the fruit-backend, fruit-client have been started
        command: |
          until kubectl get pods -l app=fruit-backend-sb -n demo | grep 1/1; do sleep 10; done
          until kubectl get pods -l app=fruit-client-sb -n demo | grep 1/1; do sleep 10; done

    - run:
        name: Push now the uber jar file of the frontend, backend
        command: |
          ./scripts/k8s_push_start.sh fruit-backend sb demo
          ./scripts/k8s_push_start.sh fruit-client sb demo

    - run:
        name: Check if the client can get the fruits from the backend/db
        command: |
          /snap/bin/microk8s.kubectl config view --raw
          export FRONTEND_ROUTE_URL=fruit-client-sb.$(minikube ip).nip.io
          curl -H "Host: fruit-client-sb" ${FRONTEND_ROUTE_URL}/api/client

workflows:
  version: 2.1
  test-component-operator-demo:
    jobs:
      - k8s-setup-start